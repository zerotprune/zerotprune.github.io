# Zero-TPrune

This is the repository that contains source code for the [Zero-TPrune website](https://zerotprune.github.io).

If you find Zero-TPrune useful for your work please cite:
```
@article{wang2023zero,
  title={Zero-TPrune: Zero-Shot Token Pruning through Leveraging of the Attention Graph in Pre-Trained Transformers},
  author={Wang, Hongjie and Dedhia, Bhishma and Jha, Niraj K.},
  journal={arXiv preprint arXiv:2305.17328},
  year={2023}
}
```

# Website License
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
